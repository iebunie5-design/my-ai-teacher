<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <title>My AI Teacher - Vercel Voice</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@stlite/mountable@0.58.0/build/stlite.css" />
</head>

<body>
    <div id="root"></div>
    <script src="https://cdn.jsdelivr.net/npm/@stlite/mountable@0.58.0/build/stlite.js"></script>
    <script>
        stlite.mount(
            {
                requirements: ["requests", "gTTS", "streamlit-mic-recorder"],
                entrypoint: "app_vercel.py",
                files: {
                    "app_vercel.py": `import streamlit as st
import requests
import json
import base64
import io
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder

st.set_page_config(page_title="My AI Teacher", page_icon="ğŸ“", layout="centered")

# [ë³´ì™„ëœ UI ë””ìì¸] ë§ˆì´í¬ ë²„íŠ¼ê³¼ ì…ë ¥ì°½ ë°°ì¹˜ë¥¼ ìœ„í•œ ìŠ¤íƒ€ì¼
st.markdown("""
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@400;600&family=Inter:wght@400;500&display=swap" rel="stylesheet">
    <style>
    [data-testid="stAppViewContainer"] { background-color: #ffffff; font-family: 'Inter', sans-serif; }
    .app-header { text-align: center; padding: 2rem 0; border-bottom: 1px solid #f1f5f9; margin-bottom: 2rem; }
    .app-header h1 { font-family: 'Outfit', sans-serif; font-size: 1.8rem; color: #0f172a; margin: 0; }
    [data-testid="stSidebar"] { background-color: #f8fafc; border-right: 1px solid #e2e8f0; }
    .stChatInputContainer { border-radius: 16px !important; box-shadow: 0 4px 12px rgba(0,0,0,0.05) !important; }
    /* ë§ˆì´í¬ì™€ ì…ë ¥ì°½ ì •ë ¬ */
    .mic-container { margin-top: 10px; display: flex; justify-content: flex-start; }
    </style>
    <div class="app-header">
        <h1>ğŸ“ My AI Teacher</h1>
        <p>Vercel Voice-Enabled Edition</p>
    </div>
    """, unsafe_allow_html=True)

if "messages" not in st.session_state: st.session_state.messages = []
if "history" not in st.session_state: st.session_state.history = []
if "last_processed_audio" not in st.session_state: st.session_state.last_processed_audio = None

with st.sidebar:
    st.markdown("### âš™ï¸ Settings")
    api_key = st.text_input("Gemini API Key", type="password")
    level = st.selectbox("Your Level", ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"])
    topic = st.selectbox("Topic", ["ìê¸°ì†Œê°œ", "ì—¬í–‰", "ì‡¼í•‘", "ìŒì‹ì ", "ì§ì¥ìƒí™œ"])
    if st.button("ğŸ”„ Start New Session"):
        st.session_state.messages = []; st.session_state.history = []; st.rerun()

# [ì¤‘ìš”] í…ìŠ¤íŠ¸ ë° ìŒì„±ì„ ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” API í•¨ìˆ˜
def call_gemini_api(prompt, api_key, audio_bytes=None):
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}
    
    parts = []
    if audio_bytes:
        # ìŒì„± ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ë‹¬
        audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
        parts.append({"inline_data": {"mime_type": "audio/wav", "data": audio_b64}})
        parts.append({"text": prompt if prompt else "Please transcribe and reply to this audio as an English teacher."})
    else:
        parts.append({"text": prompt})

    # ì „ì²´ íˆìŠ¤í† ë¦¬ì™€ í˜„ì¬ ë©”ì‹œì§€ ê²°í•©
    contents = st.session_state.history + [{"role": "user", "parts": parts}]
    data = {"contents": contents}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            result = response.json()
            ai_text = result['candidates'][0]['content']['parts'][0]['text']
            # íˆìŠ¤í† ë¦¬ì—ëŠ” í…ìŠ¤íŠ¸ ìœ„ì£¼ë¡œ ì €ì¥ (ê²½ëŸ‰í™”)
            st.session_state.history.append({"role": "user", "parts": [{"text": prompt if prompt else "[Voice Message]"}]})
            st.session_state.history.append({"role": "model", "parts": [{"text": ai_text}]})
            return ai_text
        return f"Error: {response.text}"
    except Exception as e:
        return f"Request Error: {e}"

def text_to_speech(text):
    main_text = ""
    for line in text.split('\\n'):
        if line.strip() and not any(s in line for s in ["ğŸ’¡", "ğŸ¯"]):
            main_text = line; break
    if not main_text: return None
    try:
        tts = gTTS(text=main_text, lang='en')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

if not api_key:
    st.info("Please enter your API Key in the sidebar.")
    st.stop()

# ì²« ì¸ì‚¬
if not st.session_state.messages:
    greeting = call_gemini_api(f"You are a friendly English teacher. Level: {level}, Topic: {topic}. Start the conversation warm.", api_key)
    st.session_state.messages.append({"role": "assistant", "content": greeting})

# ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg["role"] == "assistant":
            audio_fp = text_to_speech(msg["content"])
            if audio_fp: st.audio(audio_fp, format="audio/mp3")

# [ì…ë ¥ UI] ë§ˆì´í¬ì™€ í…ìŠ¤íŠ¸ ì…ë ¥ì˜ ì¡°í•©
st.markdown('<div class="mic-container">', unsafe_allow_html=True)
audio_data = mic_recorder(start_prompt="ğŸ¤ Speak to Teacher", stop_prompt="ğŸ›‘ Stop", key="mic_vercel")
st.markdown('</div>', unsafe_allow_html=True)

text_input = st.chat_input("Or type your message here...")

user_input_to_process = None
current_audio_bytes = None

# ìŒì„± ì…ë ¥ ì²˜ë¦¬
if audio_data:
    audio_id = audio_data['id'] if 'id' in audio_data else hash(audio_data['bytes'])
    if st.session_state.last_processed_audio != audio_id:
        current_audio_bytes = audio_data['bytes']
        st.session_state.last_processed_audio = audio_id

# í…ìŠ¤íŠ¸ ë˜ëŠ” ìŒì„± ì¤‘ í•˜ë‚˜ê°€ ìˆìœ¼ë©´ ì§„í–‰
if text_input:
    user_input_to_process = text_input
elif current_audio_bytes:
    user_input_to_process = None # APIì—ì„œ ì˜¤ë””ì˜¤ë¡œ ì•Œì•„ì„œ ì²˜ë¦¬ë¨

if user_input_to_process or current_audio_bytes:
    if user_input_to_process:
        st.session_state.messages.append({"role": "user", "content": user_input_to_process})
    else:
        st.session_state.messages.append({"role": "user", "content": "ğŸ™ï¸ (Voice Message sent)"})

    with st.chat_message("assistant"):
        with st.spinner("Analyzing..."):
            ai_res = call_gemini_api(user_input_to_process, api_key, current_audio_bytes)
            st.markdown(ai_res)
            audio_fp = text_to_speech(ai_res)
            if audio_fp: st.audio(audio_fp, format="audio/mp3")
            st.session_state.messages.append({"role": "assistant", "content": ai_res})
            st.rerun()`
                },
            },
            document.getElementById("root")
        );
    </script>
</body>

</html>